******scrape Project Euler Site *************
*****Step by Step ******
curl -s 'https://projecteuler.net/archives;page=1' >page1.html

< page1.html scrape -b -e 'table#problems_table > tr:not(:first-child)' >table.html

< table.html xml2json > table.json

< table.json jq -c '.html.body.tr[] | {number: .td[0][],problem: .td[2][]}' | head

< table.json jq -c '.html.body.tr[] | {id: .td[0]["$t"],subject: .td[1][]["$t"],solved:.td[2][]["$t"]}' > list.json

< list.json json2csv -p -k id,subject,solved > list.csv

head -n 11 list.csv |csvlook

*******One Line Comamnd(separated) ************
curl -s 'https://projecteuler.net/archives;page=1' |
scrape -be 'table#problems_table > tr:not(:first-child)' |
xml2json |
jq -c '.html.body.tr[] | {id: .td[0]["$t"],subject: .td[1][]["$t"],solved:.td[2][]["$t"]}' |
json2csv -p -k id,subject,solved |
head -n 11 |csvlook

******** One Line Command *********************
curl -s 'https://projecteuler.net/archives;page=1' | scrape -be 'table#problems_table > tr:not(:first-child)' | xml2json | jq -c '.html.body.tr[] | {id: .td[0]["$t"],subject: .td[1][]["$t"],solved:.td[2][]["$t"]}' | json2csv -p -k id,subject,solved | head -n 11 |csvlook

curl -s 'https://projecteuler.net/archives;page=1' | scrape -be 'table#problems_table > tr:not(:first-child)' | xml2json | jq -c '.html.body.tr[] | {id: .td[0]."$t",subject: .td[1][]."$t",solved:.td[2][]."$t"}' | json2csv -p -k id,subject,solved | head -n 11 |csvlook

==================================================================
********** scrape 2 - pe pages **********************
< ... scrape -be 'table#main_table' 
< ... scrape -be 'table#main_table > tbody>tr' 
< ... scrape -be 'table#main_table > tbody>tr:not(:first-child)'

< ... xml2json > table-...json

< ... jq -c '.html.body.tr[] | {class:.td[0]["$t"]}' | head
< ... jq -c '.html.body.tr[] | .td[]["class"]' | head
< ... jq -c '.html.body.tr[] | {id:.id,rank:.td[0]."$t",name:.td[1].table.tbody.tr.td[0].div.i."$t"}' | head
< ... jq -c '.html.body.tr[] | [.td[0]."$t",.td[1].table.tbody.tr.td[0].div.i."$t",.td[1].table.tbody.tr.td[0].div."$t"]' | head
< ... jq -c '.html.body.tr[] | [.td[0]."$t",.td[1].table.tbody.tr.td[0].div.i."$t",.td[1].table.tbody.tr.td[0].div."$t",.td[3]."$t"]' | head
< ... jq -c '.html.body.tr[] | [.td[0]."$t",.td[3]."$t",.td[1].table.tbody.tr.td[0].div.i."$t",.td[1].table.tbody.tr.td[0].div."$t"]' | head
< ... jq -c '.html.body.tr[] | [.td[0]."$t",.td[3]."$t",.td[4].a."$t",.td[1].table.tbody.tr.td[0].div.i."$t",.td[1].table.tbody.tr.td[0].div."$t",.td[1].table.tbody.tr.td[0].div.span."$t"]' | head
< ... jq -c '.html.body.tr[] | {rank:.td[0]."$t",solved:.td[3]."$t",level:.td[4].a."$t",last_solved:.td[1].table.tbody.tr.td[0].div.span."$t"}'

**** country page ******
< ... scrape -be 'table#country_table > tbody>tr'
< ... scrape -be 'table#country_table > tbody>tr:not(:first-child)' 
< ... jq -c '.html.body.tr[] | [.td[0].a."$t",.td[1]."$t",.td[2]."$t",.td[3]."$t"]' 
< ... jq -c '.html.body.tr[] | {country:.td[0].a."$t",user:.td[1]."$t",abovelv1:.td[2]."$t",mean:.td[3]."$t"}' | json2csv -p -k country,user,abovelv1,mean


************One liner ***************
< ...html scrape -be 'table#main_table > tbody>tr:not(:first-child)' | xml2json | jq -c '.html.body.tr[] | {rank:.td[0]."$t",solved:.td[3]."$t",level:.td[4].a."$t",last_solved:.td[1].table.tbody.tr.td[0].div.span."$t"}' | json2csv -p -k rank,solved,level,last_solved

*** makecsv.sh file
#!/usr/bin/env bash
FILE="$1"
< $FILE scrape -be 'table#main_table > tbody>tr:not(:first-child)' | xml2json | jq -c '.html.body.tr[] | {rank:.td[0].,solved:.td[3].,level:.td[4].a.,last_solved:.td[1].table.tbody.tr.td[0].div.span.}' | json2csv -p -k rank,solved,level,last_solved > list-one_200.csv



********************* shell script ******
#!/bin/sh
if [ $# -gt 1 ]; then
  echo 1>&2 "$0: too many arguments"
  exit 2
fi

TODAY=$(date +"%y%m%d")
FILE=${1:-list-kperson-$TODAY.csv}

if [ -f "$FILE" ];
then
   echo "File $FILE exist."
else
< Statistics\ -\ Project\ Euler-k1.html scrape -be 'table#main_table > tbody>tr:not(:first-child)' | xml2json | jq -c '.html.body.tr[] | {rank:.td[0]."$t",solved:.td[3]."$t",last_solved:.td[1].table.tbody.tr.td[0].div.span."$t"}' | json2csv -p -k rank,solved,last_solved > $FILE
for i in 2 3 4
do
< Statistics\ -\ Project\ Euler-k${i}.html scrape -be 'table#main_table > tbody>tr:not(:first-child)' | xml2json | jq -c '.html.body.tr[] | {rank:.td[0]."$t",solved:.td[3]."$t",last_solved:.td[1].table.tbody.tr.td[0].div.span."$t"}' | json2csv -k rank,solved,last_solved >> $FILE
done

fi




===========================
tfg work scrpping
***************************
scrape try :1
< work.html scrape -be 'div' | head 
< work.html scrape -be 'div' | xml2json > table_div.json

scrape try :2
< work.html scrape -be 'body>div' | head
< work.html scrape -be 'body>div' | xml2json > divTable2.json

scrape try :3
< ... scrape -be 'body>div#Page>div' > table.html
< ... scrape -be 'body>div#Page>div' > table.html 

****************************
< .... xml2json > .....
****************************
*** jq 
< divTable3.json jq -c '.html.body.div[] | {id}'
< divTable3.json jq -c '.html.body.div[] | {id,parameters}'
< divTable3.json jq -c '.html.body.div[] | {id:.["id"],parameters:.["parameters"]}'
< divTable3.json jq -c '.html.body.div[] | {id:.id,parameters:.parameters}'

< ... jq -c '.html.body.div[] | select(.id|contains("shape"))| {id:.id,param:.parameters}'
< table-ma-ld-os2-ug.json jq -c '.html.body.div[] | select(.id|contains("shape"))| .parameters|split(";")'
< table-ma-ld-os2-ug.json jq -c '.html.body.div[] | select(.id|contains("shape"))| .parameters|split(";")[0]'
< table-ma-ld-os2-ug.json jq -c '.html.body.div[] | select(.id|contains("shape"))| .parameters|split(";")[0]|split(":")'
< table-ma-ld-os2-ug.json jq -c '.html.body.div[] | select(.id|contains("shape"))| {id,param:.parameters | [split(";")[] | split(":") | {(.[0]):(.[1])}] | add}' 
