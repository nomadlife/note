vagrant command

vagrant init data-science-toolbox/data-science-at-the-command-line

turn on : vagrant up
connect : vagrant ssh
disconnect : exit
turn off : vagrant halt
delete : vagrant destroy

**shell command

head -n 3 data/movies.txt

echo 'Hello'\
> ' world' |
> wc

echo 'Hello world' | wc


fac() { (echo 1; seq $1) | paste -s -d\* | bc; }
fac 5
120

alias l='ls -1 --group-directories-first'
alias moer=more

type -a pwd
type -a cd
type -a fac
type -a l

seq 30 | grep 3
3
13
23
30

seq 100 | grep 3 | wc -l
19

seq 10 > data/ten-numbers

echo -n "Hello" > hello-world
echo " World" >> hello-world

cat hello-world | wc -w
< hello-world wc -w
wc -w hello-world

mv hello-world data
mv hello-world old-file
rm old-file
rm -r ~/book/ch02/data/old
cp server.log server.log.bak

man cat | head -n 20
help cd | head -n 20
jq --help

tar -xzvf data/logs.tar.gz

in2csv data/imdb-250.xlsx > data/imdb-250.csv
in2csv data/imdb-250.xlsx | head | cut -c1-80
in2csv data/imdb-250.xlsx | head | csvcut -c Title,Year,Rating | csvlook

sql2csv --db 'sqlite:///data/iris.db' --query 'SELECT * FROM iris WHERE sepal_length > 7.5'
sql2csv --db 'sqlite:///data/iris.db' --query 'SELECT * FROM iris WHERE sepal_length > 7.5' | csvlook

curl -s http://www.gutenberg.org/ebooks/epub/76/pg76.txt | head -n 10
 : -s for silent means diable downlaod status (currently the url not possible)
curl http://www.gutenberg.org/cache/epub/76/pg76.txt > data/finn.txt
curl -s http://www.gutenberg.org/cache/epub/76/pg76.txt -o data/finn.txt
curl -u username:password ftp://host/file

curl -L j.mp/locatbbar(-L or --location)
curl j.mp/locatbbar
curl -I j.mp/locatbbar

curl -s http://api.randomuser.me | jq '.'


********* chapter 4 make shell script

curl -s http://www.gutenberg.org/cache/epub/76/pg76.txt | tr '[:upper:]' '[:lower:]' | grep -oE '\w+' | sort | uniq -c | sort -nr | head -n 10

1. Copy and paste the one-liner into a file.
2. Add execute permissions.
3. Define a so-called shebang.
4. Remove the fixed input part.
5. Add a parameter.
6. Optionally extend your PATH.

step 1 : make file
bash ~/book/ch04/top-words-1.sh
echo "!!" > scriptname
!!

step 2 : permission
chmod u+x top-words-2.sh
ls -l top-words-{1,2}.sh
-rw-rw-r-- 1 vagrant vagrant 145 Jul 20 23:33 top-words-1.sh
-rwxrw-r-- 1 vagrant vagrant 143 Jul 20 23:34 top-words-2.sh

r:read w:wrote x:excutable
first 1 char : -:regular file d:directory
next 3 char : owner persmossions
next 3 char : group owner permissions
last 3 char : all other users permissions

./top-words-2.sh

step 3 : Define Shebang
#!/usr/bin/env bash

step 4 : Remove Fixed Input
#!/usr/bin/env bash
tr '[:upper:]' '[:lower:]' | grep -oE '\w+' | sort |
uniq -c | sort -nr | head -n 10

step 5 : Parameterize
#!/usr/bin/env bash
NUM_WORDS="$1"
tr '[:upper:]' '[:lower:]' | grep -oE '\w+' | sort |
uniq -c | sort -nr | head -n $NUM_WORDS

cat data/finn.txt | ./top-words-5.sh 5

step 6 : extend PATH vatiable
echo $PATH | fold
echo $PATH | tr : '\n' | sort
**edit the .bashrc or .profle file

** Pthon and R
#!/usr/bin/env python
from sys import stdin, stdout
while True:
line = stdin.readline()
if not line:
break
stdout.write("%d\n" % int(line)**2)
stdout.flush()

#!/usr/bin/env Rscript
f <- file("stdin")
open(f)
while(length(line <- readLines(f, n = 1)) > 0) {
write(as.integer(line)^2, stdout())
}
close(f)


********* Chapter 5 Scrubbing Data

echo 'foo\nbar\nfoo' | sort | uniq -c | sort -nr
2 foo
1 bar
--> ?? not possible. need to fix

echo 'foo\nbar\nfoo' | sort | uniq -c | sort -nr |
> awk '{print $2","$1}' | header -a value,count

value,count
foo,2
bar,1
--> ?? not possible. need to fix

cd ~/book/ch05/data
seq -f "Line %g" 10 | tee lines
Line 1
Line 2
Line 3
Line 4
Line 5
Line 6
Line 7
Line 8
Line 9
Line 10

< lines head -n 3
< lines sed -n '1,3p'
< lines awk 'NR<=3'
Line 1
Line 2
Line 3

< lines tail -n 3
Line 8
Line 9
Line 10

< lines tail -n +4
< lines sed '1,3d'
< lines sed -n '1,3!p'
Line 4
Line 5
Line 6
Line 7
Line 8
Line 9
Line 10

< lines head -n -3
Line 1
Line 2
Line 3
Line 4
Line 5
Line 6
Line 7

< lines sed -n '4,6p'
< lines awk '(NR>=4)&&(NR<=6)'
< lines head -n 6 | tail -n 3
Line 4
Line 5
Line 6

< lines sed -n '1~2p'
< lines awk 'NR%2'
Line 1
Line 3
Line 5
Line 7
Line 9

< lines sed -n '0~2p'
< lines awk '(NR+1)%2'
Line 2
Line 4
Line 6
Line 8
Line 10

**based on pattern 
grep -i chapter alice.txt
(-i means case-insensitive)
CHAPTER I. Down the Rabbit-Hole
CHAPTER II. The Pool of Tears
CHAPTER III. A Caucus-Race and a Long Tale
CHAPTER IV. The Rabbit Sends in a Little Bill
CHAPTER V. Advice from a Caterpillar
CHAPTER VI. Pig and Pepper
CHAPTER VII. A Mad Tea-Party
CHAPTER VIII. The Queen's Croquet-Ground
CHAPTER IX. The Mock Turtle's Story
CHAPTER X. The Lobster Quadrille
CHAPTER XI. Who Stole the Tarts?
CHAPTER XII. Alice's Evidence

grep -E '^CHAPTER (.*)\. The' alice.txt
-E option in order to enable regular expressions
CHAPTER II. The Pool of Tears
CHAPTER IV. The Rabbit Sends in a Little Bill
CHAPTER VIII. The Queen's Croquet-Ground
CHAPTER IX. The Mock Turtle's Story
CHAPTER X. The Lobster Quadrille

**based on randomness 
seq 1000 | sample -r 1% | jq -c '{line: .}'
{"line":69}
{"line":239}
{"line":278}
{"line":457}
{"line":480}
{"line":670}
{"line":746}
{"line":827}
{"line":850}
{"line":854}
{"line":855}
{"line":998}

seq 10000 | sample -r 1% -d 1000 -s 5 | jq -c '{line: .}'
{"line":45}
{"line":78}
{"line":299}
{"line":406}
{"line":472}
{"line":648}


** Extracting Values

grep -i chapter alice.txt | cut -d' ' -f3-
Down the Rabbit-Hole
The Pool of Tears
A Caucus-Race and a Long Tale
The Rabbit Sends in a Little Bill
Advice from a Caterpillar
Pig and Pepper
A Mad Tea-Party
The Queen's Croquet-Ground
The Mock Turtle's Story
The Lobster Quadrille
Who Stole the Tarts?
Alice's Evidence

sed -rn 's/^CHAPTER ([IVXLCDM]{1,})\. (.*)$/\2/p' alice.txt > /dev/null


grep -i chapter alice.txt | cut -c 9-
I. Down the Rabbit-Hole
II. The Pool of Tears
III. A Caucus-Race and a Long Tale
IV. The Rabbit Sends in a Little Bill
V. Advice from a Caterpillar
VI. Pig and Pepper
VII. A Mad Tea-Party
VIII. The Queen's Croquet-Ground
IX. The Mock Turtle's Story
X. The Lobster Quadrille
XI. Who Stole the Tarts?
XII. Alice's Evidence

sed -rn 's/^CHAPTER ([IVXLCDM]{1,})\. (.*)$/\2/p' alice.txt > /dev/nul

< alice.txt grep -oE '\w{2,}' | head
Project
Gutenberg
Alice
Adventures
in
Wonderland
by
Lewis
Carroll
This

< alice.txt tr '[:upper:]' '[:lower:]' | grep -oE '\w{2,}' | grep -E '^a.*e$' | sort | uniq -c | sort -nr | awk '{print $2","$1}' | header -a word,count | head | csvlook
|-------------+--------|
|  word       | count  |
|-------------+--------|
|  alice      | 403    |
|  are        | 73     |
|  archive    | 13     |
|  agree      | 11     |
|  anyone     | 5      |
|  alone      | 5      |
|  age        | 4      |
|  applicable | 3      |
|  anywhere   | 3      |
|-------------+--------|

echo 'hello world!' | tr ' ' '_'
hello_world!

echo 'hello world!' | tr ' !' '_?'
hello_world?

echo 'hello world!' | tr -d -c '[a-z]'
helloworld

echo 'hello world!' | tr '[a-z]' '[A-Z]'
echo 'hello world!' | tr '[:lower:]' '[:upper:]'
HELLO WORLD!

echo ' hello world!' | sed -re 's/hello/bye/;s/\s+/ /g;s/\s+//'
bye world!

echo -e "value\n7\n2\n5\n3" | body sort -n
seq 5 | header -a count
count
1 
2 
3 
4 
5

seq 5 | header -a count | wc -l
6

seq 5 | header -a count | body wc -l
count
5

< tips.csv header
< tips.csv head -n 1

seq 5 | header -a count
echo "count" | cat - <(seq 5)
count
1 
2 
3 
4 
5

< iris.csv header -d | head
seq 5 | header -a line | body wc -l | header -r count
count
5

seq 5 | header -a line | header -e "tr '[a-z]' '[A-Z]'"
LINE
1 
2 
3 
4 
5

< tips.csv cols head | csvlook
|--------+------+--------+--------+-----+--------+-------|
|  bill  | tip  | sex    | smoker | day | time   | size  |
|--------+------+--------+--------+-----+--------+-------|
|  16.99 | 1.01 | Female | No     | Sun | Dinner | 2     |
|  10.34 | 1.66 | Male   | No     | Sun | Dinner | 3     |
|  21.01 | 3.5  | Male   | No     | Sun | Dinner | 3     |
|  23.68 | 3.31 | Male   | No     | Sun | Dinner | 2     |
|  24.59 | 3.61 | Female | No     | Sun | Dinner | 4     |
|  25.29 | 4.71 | Male   | No     | Sun | Dinner | 4     |
|  8.77  | 2.0  | Male   | No     | Sun | Dinner | 2     |
|  26.88 | 3.12 | Male   | No     | Sun | Dinner | 4     |
|  15.04 | 1.96 | Male   | No     | Sun | Dinner | 2     |
|--------+------+--------+--------+-----+--------+-------|

< tips.csv cols -c day | head | csvlook
|---+-------+------+--------+--------+--------+-------|
|   | bill  | tip  | sex    | smoker | time   | size  |
|---+-------+------+--------+--------+--------+-------|
|   | 16.99 | 1.01 | Female | No     | Dinner | 2     |
|   | 10.34 | 1.66 | Male   | No     | Dinner | 3     |
|   | 21.01 | 3.5  | Male   | No     | Dinner | 3     |
|   | 23.68 | 3.31 | Male   | No     | Dinner | 2     |
|   | 24.59 | 3.61 | Female | No     | Dinner | 4     |
|   | 25.29 | 4.71 | Male   | No     | Dinner | 4     |
|   | 8.77  | 2.0  | Male   | No     | Dinner | 2     |
|   | 26.88 | 3.12 | Male   | No     | Dinner | 4     |
|   | 15.04 | 1.96 | Male   | No     | Dinner | 2     |
|---+-------+------+--------+--------+--------+-------|

< tips.csv cols -c day body "tr '[a-z]' '[A-Z]'" | head | csvlook
|------+-------+------+--------+--------+--------+-------|
|  DAY | bill  | tip  | sex    | smoker | time   | size  |
|------+-------+------+--------+--------+--------+-------|
|  SUN | 16.99 | 1.01 | Female | No     | Dinner | 2     |
|  SUN | 10.34 | 1.66 | Male   | No     | Dinner | 3     |
|  SUN | 21.01 | 3.5  | Male   | No     | Dinner | 3     |
|  SUN | 23.68 | 3.31 | Male   | No     | Dinner | 2     |
|  SUN | 24.59 | 3.61 | Female | No     | Dinner | 4     |
|  SUN | 25.29 | 4.71 | Male   | No     | Dinner | 4     |
|  SUN | 8.77  | 2.0  | Male   | No     | Dinner | 2     |
|  SUN | 26.88 | 3.12 | Male   | No     | Dinner | 4     |
|  SUN | 15.04 | 1.96 | Male   | No     | Dinner | 2     |
|------+-------+------+--------+--------+--------+-------|

Performing SQL Queries on CSV


seq 5 | header -a value | csvsql --query "SELECT SUM(value) AS sum FROM stdin"
sum
15

sed -e 's/"gender":/"sex":/g' data/users.json | fold | head -n 3

**********Working with HTML/XML and JSON******************
curl -sL 'http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio' > wiki.html

head -n 10 data/wiki.html | cut -c1-79
< wiki.html grep wikitable -A 21
< wiki.html scrape -b -e 'table.wikitable > tr:not(:first-child)' > table.html
head -n 21 data/table.html

< table.html xml2json > table.json
< table.json jq '.' | head -n 25

< table.json jq -c '.html.body.tr[] | {country: .td[1][],border:.td[2][], surface: .td[3][]}' > countries.json
head -n 10 data/countries.json
head -n 11 countries.csv | csvlook
*************************

curl -sL 'http://en.wikipedia.org/wiki/List_of_countries'\
> '_and_territories_by_border/area_ratio' |
> scrape -be 'table.wikitable > tr:not(:first-child)' |
> xml2json | jq -c '.html.body.tr[] | {country: .td[1][],'\
> 'border: .td[2][], surface: .td[3][], ratio: .td[4][]}' |
> json2csv -p -k=border,surface | head -n 11 | csvlook

